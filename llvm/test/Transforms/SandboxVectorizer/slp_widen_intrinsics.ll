; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 3
; RUN: opt -passes=sandbox-vectorizer -sbvec-vec-reg-bits=512 -sbvec-cost-threshold=-9999 %s -S | FileCheck %s --check-prefix=VECTOR
; RUN: opt -passes=sandbox-vectorizer -sbvec-vec-reg-bits=512 -sbvec-cost-threshold=99999 %s -S | FileCheck %s --check-prefix=SCALAR

; For now we are not vecotrizing intrinsics.

declare double @llvm.sqrt.f64(double)

define void @dont_widen_intrinsics(ptr %ptr, double %d0, double %d1) {
;
; VECTOR-LABEL: define void @dont_widen_intrinsics(
; VECTOR-SAME: ptr [[PTR:%.*]], double [[D0:%.*]], double [[D1:%.*]]) {
; VECTOR-NEXT:    [[PTR0:%.*]] = getelementptr double, ptr [[PTR]], i32 0
; VECTOR-NEXT:    [[V0:%.*]] = call double @llvm.sqrt.f64(double [[D0]])
; VECTOR-NEXT:    [[V1:%.*]] = call double @llvm.sqrt.f64(double [[D1]])
; VECTOR-NEXT:    [[PACK:%.*]] = insertelement <2 x double> poison, double [[V0]], i64 0
; VECTOR-NEXT:    [[PACK1:%.*]] = insertelement <2 x double> [[PACK]], double [[V1]], i64 1
; VECTOR-NEXT:    store <2 x double> [[PACK1]], ptr [[PTR0]], align 8
; VECTOR-NEXT:    ret void
;
; SCALAR-LABEL: define void @dont_widen_intrinsics(
; SCALAR-SAME: ptr [[PTR:%.*]], double [[D0:%.*]], double [[D1:%.*]]) {
; SCALAR-NEXT:    [[PTR0:%.*]] = getelementptr double, ptr [[PTR]], i32 0
; SCALAR-NEXT:    [[PTR1:%.*]] = getelementptr double, ptr [[PTR]], i32 1
; SCALAR-NEXT:    [[V0:%.*]] = call double @llvm.sqrt.f64(double [[D0]])
; SCALAR-NEXT:    [[V1:%.*]] = call double @llvm.sqrt.f64(double [[D1]])
; SCALAR-NEXT:    store double [[V0]], ptr [[PTR0]], align 8
; SCALAR-NEXT:    store double [[V1]], ptr [[PTR1]], align 8
; SCALAR-NEXT:    ret void
;
  %ptr0 = getelementptr double, ptr %ptr, i32 0
  %ptr1 = getelementptr double, ptr %ptr, i32 1
  %v0 = call double @llvm.sqrt.f64(double %d0)
  %v1 = call double @llvm.sqrt.f64(double %d1)
  store double %v0, ptr %ptr0
  store double %v1, ptr %ptr1
  ret void
}
